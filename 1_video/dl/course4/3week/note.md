第四部分第三周

下面三种问题是不一样的：

图片分类
定位分类
对象检测
对于前两种问题，输入的图片中通常只包含一个对象，而对第三种问题，可能包含多个对象。

对于图片分类问题，把图片输入卷积网络中，输出是 softmax 的几个值。

对于定位分类问题，输出时还要加上$p_c$属性，描述图片中是否有对象。

再加上 $b_x,b_y,b_h,b_w$ 几个属性，用来定义对象所在的矩形框。这四个值都在0到1之间。

图片左上角与右下角的坐标分别为 (0,0) 和 (1,1)。

$b_x,b_y$ 定义矩形的中心位置。$b_h,b_w$定义矩形的高和宽。

定义损失函数时，如果 $p_c$ 为 1，就可以定义为 8 个分量的平方差的和，否则定义为 $(y_1^{\hat{}}-y_1)^2$。

也不一定都要用平方差，而是可以对输出中的不同分量，用不同的损失函数，比如对 softmax 的输出用？？？，对边界框的四个值用平方差。

Landmark Detection

把图片输入卷积网络，可以在输出里加一些 landmark 点，用 $l_{1x},l_{1y},...,l_{64x},l_{64y}$ 表示。

多个不同图片的 landmark 点，含义的顺序要相同。

landmark 点的标注通常是花钱让劳动力来做的。

Object Detection

先用只有单个对象的小图片训练出一个卷积网络。

再对大图片做滑动窗口，遍历一遍图片，找到目标对象的位置。

窗口尺寸从小到大，每个尺寸都做一遍遍历。

这个方法的缺点是计算量太大。

Convolutional Implementation of Sliding Windows

论文：Sermanet et al., 2014, OverFeat: Integrated recognition, localization & detection using convolutional networkds

由于对每个窗口尺寸都做一次遍历图片，计算量太大，于是有人提出用卷积的方法来做滑动窗口。

首先要把 FC 层换成卷积层。

例如，对于 400 个节点的 FC 层，可以用 400 个 5 * 5 * 16 的过滤器，生成一个 1 * 1 * 400 的层来代替。

对于输出的 softmax 层，可以用 4 个 1 * 1 * 400 的过滤器，生成一个 1 * 1 * 4 的层来代替。

换完了以后，我就开始看不懂了。

我看了别人的笔记，大概意思是，对于一张大图片，本来需要分割成4张图片来做，所以效率低。

但是把 FC 层改成卷积层以后，就不用分割，像原来一样做就行，最后的结果会是原来的四倍。

中间会有很多计算是共享的，所以效率提高了。

（具体怎么共享的，我也不知道。）

最后，这个算法有个缺点，边界框的位置不准确。

Bounding Box Predictions

论文：Redmon et al., 2015, You Only Look Once: Unified real-time object detection

把图片分割为 3 * 3，对图片里的每个对象，找到他的中心点，在哪个小块，就算哪个小块的 $p_c$ 为 1。

这里的 $b_x,b_y$ 都是 0 到 1 之间的数。

但是 $b_h,b_w$ 可以为大于 1 的数。因为是以小格子为 1 的尺度。

Intersection Over Union

两个方框的交的面积除以并的面积，得到的就是交并比。

一般认为，如果这个比值大于 0.5，就代表定位正确。

也可以把数字调大，让要求更严格一些。
