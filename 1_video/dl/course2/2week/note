mini-batch梯度下降法
x=[x(1) x（2）... x(m)]  训练样本
（nx,m）纬度
Y=[y(1) y（2）... y(m)]  样本结果
（1，m）
把整个训练样本集分成多个训练集（mini-batch）
相应也要拆分y
for t =1， ......5000
 Z[1]=W[1]X{t}+b[1]
 A[1]=g[1](Z[1])
 .....
 A[l] = g[l](Z[l])  设计为1000个样本
 cost j = 1/1000
 w[l]:=w[l]-adw[l], b[l]:=b[l]-adb[l]
 

随机梯度下降法缺点：失去向量带给你带加速